<!DOCTYPE html>
<html lang="en"><head><title>Transformers</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Transformers"/><meta property="og:description" content="Source: arxiv.org/pdf/1706.03762 Attention Scaled Dot-Production Attention Attention function is described as mapping a query and a set of key-value pairs to an output ..."/><meta property="og:image" content="static/og-image.png"/> <meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="Source: arxiv.org/pdf/1706.03762 Attention Scaled Dot-Production Attention Attention function is described as mapping a query and a set of key-value pairs to an output ..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script></head><body data-slug="Large-Model-Systems/Transformers"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href="..">üìù Notes</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="search-layout" data-preview="true"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabindex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35" xml:space="preserve"><title>Dark mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabindex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background:new 0 0 100 100" xml:space="preserve"><title>Light mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div><div class="explorer desktop-only"><button type="button" id="explorer" data-behavior="collapse" data-collapsed="collapsed" data-savestate="true" data-tree="[{&quot;path&quot;:&quot;Advance-Energy-Systems&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Biology&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Computer-Architecture&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Computer-Vision&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Cryptography&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;CUDA&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Data-Structures-and-Algos&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Economics&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Education&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Large-Model-Systems&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Linux-Kernel-Development&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Memory&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;MRI&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Political-Theory&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Psychology&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Religion&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Religion/Bible&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Religion/Bible/Genesis&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Screenplay-Writing&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;Verilog&quot;,&quot;collapsed&quot;:true}]"><h1>Explorer</h1><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="explorer-content"><ul class="overflow" id="explorer-ul"><li><div class="folder-outer open"><ul style="padding-left:0;" class="content" data-folderul><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Advance-Energy-Systems"><button class="folder-button"><span class="folder-title">Advance Energy Systems</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Advance-Energy-Systems"><li><a href="../Advance-Energy-Systems/control-rods" data-for="Advance-Energy-Systems/control-rods">control rods</a></li><li><a href="../Advance-Energy-Systems/Dyson-Spheres" data-for="Advance-Energy-Systems/Dyson-Spheres">Dyson Spheres</a></li><li><a href="../Advance-Energy-Systems/Fission-Reaction" data-for="Advance-Energy-Systems/Fission-Reaction">Fission Reaction</a></li><li><a href="../Advance-Energy-Systems/gaseous-diffusion" data-for="Advance-Energy-Systems/gaseous-diffusion">gaseous diffusion</a></li><li><a href="../Advance-Energy-Systems/moderator" data-for="Advance-Energy-Systems/moderator">moderator</a></li><li><a href="../Advance-Energy-Systems/Neutron-Scattering" data-for="Advance-Energy-Systems/Neutron-Scattering">Neutron Scattering</a></li><li><a href="../Advance-Energy-Systems/Nuclear-Power-Plants" data-for="Advance-Energy-Systems/Nuclear-Power-Plants">Nuclear Power Plants</a></li><li><a href="../Advance-Energy-Systems/Nuclear-Reactor" data-for="Advance-Energy-Systems/Nuclear-Reactor">Nuclear Reactor</a></li><li><a href="../Advance-Energy-Systems/The-Grid" data-for="Advance-Energy-Systems/The-Grid">The Grid</a></li><li><a href="../Advance-Energy-Systems/uranium-enrichment" data-for="Advance-Energy-Systems/uranium-enrichment">uranium enrichment</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Biology"><button class="folder-button"><span class="folder-title">Biology</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Biology"><li><a href="../Biology/The-Genetic-Code" data-for="Biology/The-Genetic-Code">The Genetic Code</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Computer-Architecture"><button class="folder-button"><span class="folder-title">Computer Architecture</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Computer-Architecture"><li><a href="../Computer-Architecture/AC" data-for="Computer-Architecture/AC">AC</a></li><li><a href="../Computer-Architecture/ARM-architecture" data-for="Computer-Architecture/ARM-architecture">ARM architecture</a></li><li><a href="../Computer-Architecture/CMOS" data-for="Computer-Architecture/CMOS">CMOS</a></li><li><a href="../Computer-Architecture/Compute-in-Memory-(CIM)" data-for="Computer-Architecture/Compute-in-Memory-(CIM)">Compute-in-Memory (CIM)</a></li><li><a href="../Computer-Architecture/Computer-Architecture" data-for="Computer-Architecture/Computer-Architecture">Computer Architecture</a></li><li><a href="../Computer-Architecture/inverter" data-for="Computer-Architecture/inverter">inverter</a></li><li><a href="../Computer-Architecture/NMOS" data-for="Computer-Architecture/NMOS">NMOS</a></li><li><a href="../Computer-Architecture/Parallel-Processors" data-for="Computer-Architecture/Parallel-Processors">Parallel Processors</a></li><li><a href="../Computer-Architecture/PMOS" data-for="Computer-Architecture/PMOS">PMOS</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Computer-Vision"><button class="folder-button"><span class="folder-title">Computer Vision</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Computer-Vision"><li><a href="../Computer-Vision/Slam" data-for="Computer-Vision/Slam">Slam</a></li></ul></div></li><li><div class="folder-outer "><ul style="padding-left:0;" class="content" data-folderul></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Cryptography"><button class="folder-button"><span class="folder-title">Cryptography</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Cryptography"><li><a href="../Cryptography/Cryptography" data-for="Cryptography/Cryptography">Cryptography</a></li><li><a href="../Cryptography/Mono-alphabetic-substition" data-for="Cryptography/Mono-alphabetic-substition">Mono-alphabetic substition</a></li><li><a href="../Cryptography/STARKs" data-for="Cryptography/STARKs">STARKs</a></li><li><a href="../Cryptography/The-Vigen√®re-(poly-alphabetic-shift)-cipher" data-for="Cryptography/The-Vigen√®re-(poly-alphabetic-shift)-cipher">The Vigen√®re (poly-alphabetic shift) cipher</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="CUDA"><button class="folder-button"><span class="folder-title">CUDA</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="CUDA"><li><a href="../CUDA/3-component-vector-that-represent-the-thread-index-within-a-block-1" data-for="CUDA/3-component-vector-that-represent-the-thread-index-within-a-block-1">3-component vector that represent the thread index within a block 1</a></li><li><a href="../CUDA/CUDA" data-for="CUDA/CUDA">CUDA</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Data-Structures-and-Algos"><button class="folder-button"><span class="folder-title">Data Structures and Algos</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Data-Structures-and-Algos"><li><a href="../Data-Structures-and-Algos/KD-Tree" data-for="Data-Structures-and-Algos/KD-Tree">KD Tree</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Economics"><button class="folder-button"><span class="folder-title">Economics</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Economics"><li><a href="../Economics/Wealth-of-Nations" data-for="Economics/Wealth-of-Nations">Wealth of Nations</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Education"><button class="folder-button"><span class="folder-title">Education</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Education"></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Large-Model-Systems"><button class="folder-button"><span class="folder-title">Large Model Systems</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Large-Model-Systems"><li><a href="../Large-Model-Systems/1-bit-LLMs" data-for="Large-Model-Systems/1-bit-LLMs">1 bit LLMs</a></li><li><a href="../Large-Model-Systems/Allreduce" data-for="Large-Model-Systems/Allreduce">Allreduce</a></li><li><a href="../Large-Model-Systems/CLIP" data-for="Large-Model-Systems/CLIP">CLIP</a></li><li><a href="../Large-Model-Systems/CUDA-API-of-GPT-2" data-for="Large-Model-Systems/CUDA-API-of-GPT-2">CUDA API of GPT 2</a></li><li><a href="../Large-Model-Systems/Deep-Dive-of-GPT-architecture" data-for="Large-Model-Systems/Deep-Dive-of-GPT-architecture">Deep Dive of GPT architecture</a></li><li><a href="../Large-Model-Systems/Gemini" data-for="Large-Model-Systems/Gemini">Gemini</a></li><li><a href="../Large-Model-Systems/How-a-Transformer-works-at-inference-vs-training-time" data-for="Large-Model-Systems/How-a-Transformer-works-at-inference-vs-training-time">How a Transformer works at inference vs training time</a></li><li><a href="../Large-Model-Systems/IEEE-754" data-for="Large-Model-Systems/IEEE-754">IEEE-754</a></li><li><a href="../Large-Model-Systems/Liger-Kernels" data-for="Large-Model-Systems/Liger-Kernels">Liger Kernels</a></li><li><a href="../Large-Model-Systems/LlaMa-from-scratch" data-for="Large-Model-Systems/LlaMa-from-scratch">LlaMa from scratch</a></li><li><a href="../Large-Model-Systems/LLaVA" data-for="Large-Model-Systems/LLaVA">LLaVA</a></li><li><a href="../Large-Model-Systems/MatMul-Free-Language-Modeling" data-for="Large-Model-Systems/MatMul-Free-Language-Modeling">MatMul-Free Language Modeling</a></li><li><a href="../Large-Model-Systems/ML-Interpretability" data-for="Large-Model-Systems/ML-Interpretability">ML Interpretability</a></li><li><a href="../Large-Model-Systems/Optical-Circuit-Switches" data-for="Large-Model-Systems/Optical-Circuit-Switches">Optical Circuit Switches</a></li><li><a href="../Large-Model-Systems/Positional-embeddings-matrix" data-for="Large-Model-Systems/Positional-embeddings-matrix">Positional embeddings matrix</a></li><li><a href="../Large-Model-Systems/Post-Training-Static-quantization" data-for="Large-Model-Systems/Post-Training-Static-quantization">Post-Training Static quantization</a></li><li><a href="../Large-Model-Systems/Quantization" data-for="Large-Model-Systems/Quantization">Quantization</a></li><li><a href="../Large-Model-Systems/queries-(Q),-keys-(K),-and-values-(V)" data-for="Large-Model-Systems/queries-(Q),-keys-(K),-and-values-(V)">queries (Q), keys (K), and values (V)</a></li><li><a href="../Large-Model-Systems/Silent-Data-Corruption-(SDC)" data-for="Large-Model-Systems/Silent-Data-Corruption-(SDC)">Silent Data Corruption (SDC)</a></li><li><a href="../Large-Model-Systems/Softmax" data-for="Large-Model-Systems/Softmax">Softmax</a></li><li><a href="../Large-Model-Systems/SparseCore" data-for="Large-Model-Systems/SparseCore">SparseCore</a></li><li><a href="../Large-Model-Systems/SSM-vs-Transformer" data-for="Large-Model-Systems/SSM-vs-Transformer">SSM vs Transformer</a></li><li><a href="../Large-Model-Systems/Token-embeddings-matrix" data-for="Large-Model-Systems/Token-embeddings-matrix">Token embeddings matrix</a></li><li><a href="../Large-Model-Systems/Tokenization" data-for="Large-Model-Systems/Tokenization">Tokenization</a></li><li><a href="../Large-Model-Systems/Torchserve" data-for="Large-Model-Systems/Torchserve">Torchserve</a></li><li><a href="../Large-Model-Systems/TPUv4" data-for="Large-Model-Systems/TPUv4">TPUv4</a></li><li><a href="../Large-Model-Systems/Training-GPT-from-Scratch" data-for="Large-Model-Systems/Training-GPT-from-Scratch">Training GPT from Scratch</a></li><li><a href="../Large-Model-Systems/Transformers" data-for="Large-Model-Systems/Transformers">Transformers</a></li><li><a href="../Large-Model-Systems/Vector-matrix-multiplication-(VMM)" data-for="Large-Model-Systems/Vector-matrix-multiplication-(VMM)">Vector-matrix multiplication (VMM)</a></li><li><a href="../Large-Model-Systems/VIdeo-understanding" data-for="Large-Model-Systems/VIdeo-understanding">VIdeo understanding</a></li><li><a href="../Large-Model-Systems/Vision-Transformer" data-for="Large-Model-Systems/Vision-Transformer">Vision Transformer</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Linux-Kernel-Development"><button class="folder-button"><span class="folder-title">Linux Kernel Development</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Linux-Kernel-Development"><li><a href="../Linux-Kernel-Development/linux_kernel_development" data-for="Linux-Kernel-Development/linux_kernel_development">linux_kernel_development</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Memory"><button class="folder-button"><span class="folder-title">Memory</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Memory"><li><a href="../Memory/Memory" data-for="Memory/Memory">Memory</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="MRI"><button class="folder-button"><span class="folder-title">MRI</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="MRI"></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Political-Theory"><button class="folder-button"><span class="folder-title">Political Theory</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Political-Theory"><li><a href="../Political-Theory/Political-Theory" data-for="Political-Theory/Political-Theory">Political Theory</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Psychology"><button class="folder-button"><span class="folder-title">Psychology</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Psychology"><li><a href="../Psychology/Developmental-Psychology" data-for="Psychology/Developmental-Psychology">Developmental Psychology</a></li><li><a href="../Psychology/Erickson" data-for="Psychology/Erickson">Erickson</a></li><li><a href="../Psychology/Piaget" data-for="Psychology/Piaget">Piaget</a></li><li><a href="../Psychology/Vygotsky" data-for="Psychology/Vygotsky">Vygotsky</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Religion"><button class="folder-button"><span class="folder-title">Religion</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Religion"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Religion/Bible"><button class="folder-button"><span class="folder-title">Bible</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Religion/Bible"><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Religion/Bible/Genesis"><button class="folder-button"><span class="folder-title">Genesis</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Religion/Bible/Genesis"><li><a href="../Religion/Bible/Genesis/Genesis" data-for="Religion/Bible/Genesis/Genesis">Genesis</a></li><li><a href="../Religion/Bible/Genesis/Genesis-1-2" data-for="Religion/Bible/Genesis/Genesis-1-2">Genesis 1-2</a></li><li><a href="../Religion/Bible/Genesis/Genesis-3" data-for="Religion/Bible/Genesis/Genesis-3">Genesis 3</a></li><li><a href="../Religion/Bible/Genesis/Genesis-4-5" data-for="Religion/Bible/Genesis/Genesis-4-5">Genesis 4-5</a></li><li><a href="../Religion/Bible/Genesis/Genesis-6-9" data-for="Religion/Bible/Genesis/Genesis-6-9">Genesis 6-9</a></li><li><a href="../Religion/Bible/Genesis/Genesis-10-11" data-for="Religion/Bible/Genesis/Genesis-10-11">Genesis 10-11</a></li><li><a href="../Religion/Bible/Genesis/Genesis-12-25" data-for="Religion/Bible/Genesis/Genesis-12-25">Genesis 12-25</a></li><li><a href="../Religion/Bible/Genesis/Genesis-26-27" data-for="Religion/Bible/Genesis/Genesis-26-27">Genesis 26-27</a></li><li><a href="../Religion/Bible/Genesis/Genesis-28-36" data-for="Religion/Bible/Genesis/Genesis-28-36">Genesis 28-36</a></li><li><a href="../Religion/Bible/Genesis/Genesis-37-50" data-for="Religion/Bible/Genesis/Genesis-37-50">Genesis 37-50</a></li></ul></div></li><li><a href="../Religion/Bible/Bible" data-for="Religion/Bible/Bible">Bible</a></li></ul></div></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Screenplay-Writing"><button class="folder-button"><span class="folder-title">Screenplay Writing</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Screenplay-Writing"><li><a href="../Screenplay-Writing/Screenplay-Course" data-for="Screenplay-Writing/Screenplay-Course">Screenplay Course</a></li></ul></div></li><li><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="Verilog"><button class="folder-button"><span class="folder-title">Verilog</span></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="Verilog"><li><a href="../Verilog/learning_verilog" data-for="Verilog/learning_verilog">learning_verilog</a></li></ul></div></li><li><a href="../2024-09-23" data-for="2024-09-23">2024-09-23</a></li><li><a href="../Links" data-for="Links">Links</a></li></ul></div></li><li id="explorer-end"></li></ul></div></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Home</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href="../Large-Model-Systems/">Large Model Systems</a><p> ‚ùØ </p></div><div class="breadcrumb-element"><a href>Transformers</a></div></nav><h1 class="article-title">Transformers</h1><p show-comma="true" class="content-meta"><span>Nov 05, 2025</span><span>4 min read</span></p></div></div><article class="popover-hint"><p>Source: <a href="https://arxiv.org/pdf/1706.03762" class="external">https://arxiv.org/pdf/1706.03762<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<h2 id="attention">Attention<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#attention" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="scaled-dot-production-attention">Scaled Dot-Production Attention<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#scaled-dot-production-attention" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><strong>Attention</strong> function is described as mapping a query and a set of key-value pairs to an output. Output is a weighted sum of the values weighting assigned to each values is computated by a compatibility function of the query with the corresponding keys</p>
<p><strong>Details</strong>:</p>
<ul>
<li><strong>Inputs</strong>: The inputs to the attention mechanism are <a href="../Large-Model-Systems/queries-(Q),-keys-(K),-and-values-(V)" class="internal alias" data-slug="Large-Model-Systems/queries-(Q),-keys-(K),-and-values-(V)">queries (Q), keys (K), and values (V)</a>. These are all vectors. In the context of the Transformer, these vectors are usually outputs from the previous layer of the model.</li>
<li><strong>Dot Products of Queries and Keys</strong>: The first step in calculating attention is to find the dot products of the query with all keys. This represents a measure of compatibility or similarity, with higher values indicating greater compatibility.</li>
<li><strong>Scaling</strong>: Each dot product is scaled by the inverse square root of the dimension of the keys, <span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3831em;vertical-align:-0.538em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>. This scaling factor helps prevent the dot product values from growing too large in magnitude, which can lead to computational instability due to the <a href="../Large-Model-Systems/Softmax" class="internal" data-slug="Large-Model-Systems/Softmax">Softmax</a> function operating in regions where it has extremely small gradients.</li>
<li><strong>Softmax</strong>: Next, a softmax function is applied to the scaled dot products. This step converts the scores into probabilities that sum to one. The softmax essentially picks out the highest scores, magnifying their importance.</li>
<li><strong>Output</strong>: The output is computed as a weighted sum of the values V. Each value is weighted by the softmax score, ensuring that values corresponding to more compatible keys contribute more to the result.</li>
</ul>
<p><strong>Equation</strong>
<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Attention(Q,K,V)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1072em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></p>
<h3 id="example-setup">Example setup<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#example-setup" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>For our example, let‚Äôs consider the simple sentence: <strong>‚ÄúThe quick brown fox jumps.‚Äù</strong></p>
<h3 id="step-1-tokenization">Step 1: Tokenization<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#step-1-tokenization" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>The first step in processing this sentence for a model like the Transformer is tokenization. Tokenization is the process of splitting the text into manageable pieces or tokens. Depending on the model setup, this could be words, subwords, or even characters. For simplicity, let‚Äôs assume word-level tokenization here:</p>
<ul>
<li>Tokens: [‚ÄúThe‚Äù, ‚Äúquick‚Äù, ‚Äúbrown‚Äù, ‚Äúfox‚Äù, ‚Äújumps‚Äù]</li>
</ul>
<h3 id="step-2-embedding">Step 2: Embedding<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#step-2-embedding" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Each token is then converted into a numerical form known as an embedding. These embeddings are typically learned during training and are capable of capturing semantic meanings of the words. Suppose we‚Äôre using an embedding dimension of 4 for simplicity (real models use much larger dimensions like 512). After embedding, each word might be represented as follows:</p>
<ul>
<li>‚ÄúThe‚Äù: [0.1,0.2,0.3,0.4][0.1,0.2,0.3,0.4]</li>
<li>‚Äúquick‚Äù: [0.5,0.6,0.7,0.8][0.5,0.6,0.7,0.8]</li>
<li>‚Äúbrown‚Äù: [0.9,1.0,1.1,1.2][0.9,1.0,1.1,1.2]</li>
<li>‚Äúfox‚Äù: [1.3,1.4,1.5,1.6][1.3,1.4,1.5,1.6]</li>
<li>‚Äújumps‚Äù: [1.7,1.8,1.9,2.0][1.7,1.8,1.9,2.0]</li>
</ul>
<h3 id="step-3-generating-queries-keys-and-values">Step 3: Generating Queries, Keys, and Values<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#step-3-generating-queries-keys-and-values" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>In the Transformer, each token‚Äôs embedding is used to generate queries, keys, and values. This is done through different linear transformations (i.e., different sets of weights). For simplicity, let‚Äôs assume these transformations just reshape the embeddings a bit (in practice, they would be learned matrices). We‚Äôll use simplified transformations:</p>
<ul>
<li><strong>Queries (Q)</strong>, <strong>Keys (K)</strong>, and <strong>Values (V)</strong> might end up looking something like:
<ul>
<li>‚ÄúThe‚Äù: Q=[0.1,0.2],K=[0.2,0.1],V=[0.3,0.4]</li>
<li>‚Äúquick‚Äù: Q=[0.5,0.6],K=[0.6,0.5],V=[0.7,0.8]</li>
<li>‚Äúbrown‚Äù: Q=[0.9,1.0],K=[1.0,0.9],V=[1.1,1.2]</li>
<li>‚Äúfox‚Äù: Q=[1.3,1.4],K=[1.4,1.3],V=[1.5,1.6]</li>
<li>‚Äújumps‚Äù: Q=[1.7,1.8],K=[1.8,1.7],V=[1.9,2.0]</li>
</ul>
</li>
</ul>
<h3 id="step-4-calculating-attention-for-one-word">Step 4: Calculating Attention for One Word<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#step-4-calculating-attention-for-one-word" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Let‚Äôs focus on calculating the attention for the word ‚Äúquick‚Äù:</p>
<ul>
<li>Compute dot products of ‚Äúquick‚Äù query with all keys to measure compatibility.</li>
<li>Apply a scaling factor and softmax to these scores to get probabilities.</li>
<li>Use these probabilities to compute a weighted sum of the values, which gives you the attention output for ‚Äúquick‚Äù.</li>
</ul>
<h3 id="visualization">Visualization:<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#visualization" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>This process essentially allows the model to ‚Äúattend‚Äù to all words in the sentence when processing the word ‚Äúquick‚Äù, but to varying degrees based on how relevant each word is to ‚Äúquick‚Äù (as determined by the softmax scores of their dot products).</p>
<h2 id="practical-application-in-transformer">Practical application in transformer<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#practical-application-in-transformer" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>In the Transformer, this attention mechanism is used in three different ways:</p>
<ol>
<li><strong>Encoder self-attention</strong>: Each position in the encoder can attend to all positions in the previous layer of the encoder.</li>
<li><strong>Decoder self-attention</strong>: Each position in the decoder can attend to all positions up to and including that position in the decoder, using masking to preserve causality.</li>
<li><strong>Encoder-decoder attention</strong>: Queries from the decoder attend to all positions in the encoder.</li>
</ol>
<h2 id="how-a-transformer-works-at-inference-vs-training-time"><a href="../Large-Model-Systems/How-a-Transformer-works-at-inference-vs-training-time" class="internal alias" data-slug="Large-Model-Systems/How-a-Transformer-works-at-inference-vs-training-time">How a Transformer works at inference vs training time</a><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#how-a-transformer-works-at-inference-vs-training-time" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<hr/>
<p>source: <a href="https://www.youtube.com/watch?v=ISNdQcPhsts" class="external">https://www.youtube.com/watch?v=ISNdQcPhsts<svg class="external-icon" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></p>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled/> Inouts <span>‚Üí</span> Input Embeddings yo</li>
</ul></article></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:false}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xml:space="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[],&quot;focusOnHover&quot;:true}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#attention" data-for="attention">Attention</a></li><li class="depth-1"><a href="#scaled-dot-production-attention" data-for="scaled-dot-production-attention">Scaled Dot-Production Attention</a></li><li class="depth-1"><a href="#example-setup" data-for="example-setup">Example setup</a></li><li class="depth-1"><a href="#step-1-tokenization" data-for="step-1-tokenization">Step 1: Tokenization</a></li><li class="depth-1"><a href="#step-2-embedding" data-for="step-2-embedding">Step 2: Embedding</a></li><li class="depth-1"><a href="#step-3-generating-queries-keys-and-values" data-for="step-3-generating-queries-keys-and-values">Step 3: Generating Queries, Keys, and Values</a></li><li class="depth-1"><a href="#step-4-calculating-attention-for-one-word" data-for="step-4-calculating-attention-for-one-word">Step 4: Calculating Attention for One Word</a></li><li class="depth-1"><a href="#visualization" data-for="visualization">Visualization:</a></li><li class="depth-0"><a href="#practical-application-in-transformer" data-for="practical-application-in-transformer">Practical application in transformer</a></li><li class="depth-0"><a href="#how-a-transformer-works-at-inference-vs-training-time" data-for="how-a-transformer-works-at-inference-vs-training-time">How a Transformer works at inference vs training time</a></li></ul></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="../Large-Model-Systems/Deep-Dive-of-GPT-architecture" class="internal">Deep Dive of GPT architecture</a></li><li><a href="../Large-Model-Systems/" class="internal">Large Model Systems</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.2.3</a> ¬© 2025</p><ul><li><a href="https://github.com/viraatdas/notes">GitHub</a></li></ul></footer></div></body><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">function c(){let t=this.parentElement;t.classList.toggle("is-collapsed");let l=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=l+"px";let o=t,e=t.parentElement;for(;e;){if(!e.classList.contains("callout"))return;let n=e.classList.contains("is-collapsed")?e.scrollHeight:e.scrollHeight+o.scrollHeight;e.style.maxHeight=n+"px",o=e,e=e.parentElement}}function i(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let l=s.firstElementChild;if(l){l.addEventListener("click",c),window.addCleanup(()=>l.removeEventListener("click",c));let e=s.classList.contains("is-collapsed")?l.scrollHeight:s.scrollHeight;s.style.maxHeight=e+"px"}}}document.addEventListener("nav",i);window.addEventListener("resize",i);
</script><script type="module">
          let mermaidImport = undefined
          document.addEventListener('nav', async () => {
            if (document.querySelector("code.mermaid")) {
              mermaidImport ||= await import('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs')
              const mermaid = mermaidImport.default
              const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
              mermaid.initialize({
                startOnLoad: false,
                securityLevel: 'loose',
                theme: darkMode ? 'dark' : 'default'
              })

              await mermaid.run({
                querySelector: '.mermaid'
              })
            }
          });
          </script><script src="../postscript.js" type="module"></script></html>